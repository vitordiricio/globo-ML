import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import statsmodels.api as sm

def analise_externos(df):
    """
        Analyzes external factors' impact on TV Linear data, including economic indicators,
        specific events, and social metrics."
        Args:
        df (DataFrame): Processed dataframe with EXTERNO_ and LINEAR_ prefixed columns
    """

    st.header("üìä Fatores Externos - Impacto na Audi√™ncia")

    # 1. Header section with last update date
    if 'data_hora' in df.columns:
        last_date = df['data_hora'].max()
        if isinstance(last_date, pd.Timestamp):
            last_date = last_date.to_pydatetime()
        st.caption(f"√öltima atualiza√ß√£o: {last_date.strftime('%d/%m/%Y')}")

    # Ensure data_hora is datetime type
    if 'data_hora' in df.columns and not pd.api.types.is_datetime64_dtype(df['data_hora']):
        df['data_hora'] = pd.to_datetime(df['data_hora'])

    # Create copies of the dataframe for each granularity

    # Use original dataframe for hourly analysis
    df_hourly = df.copy()

    # Create daily aggregation
    df_daily = df.copy()
    df_daily['data'] = df_daily['data_hora'].dt.date

    # Filter numeric columns for aggregation (to avoid categorical type error)
    numeric_cols = df_daily.select_dtypes(include=['number']).columns.tolist()
    if 'data' in numeric_cols:
        numeric_cols.remove('data')

    # Group by date for numeric columns only
    df_daily = df_daily.groupby('data')[numeric_cols].mean().reset_index()
    df_daily['data_hora'] = pd.to_datetime(df_daily['data'])

    # Create weekly aggregation
    df_weekly = df.copy()
    df_weekly['semana'] = df_weekly['data_hora'].dt.to_period('W').astype(str)

    # Group by week for numeric columns only
    df_weekly = df_weekly.groupby('semana')[numeric_cols].mean().reset_index()
    df_weekly['data_hora'] = pd.to_datetime(df_weekly['semana'].str.split('/').str[0])

    # 2. Granularity Selection
    st.markdown("""
    ### An√°lise de Fatores Externos

    Esta an√°lise explora como fatores externos impactam a audi√™ncia da TV Linear da Globo. 
    Investigamos tr√™s categorias principais:

    1. **Indicadores Econ√¥micos**: Como infla√ß√£o, desemprego e outros √≠ndices econ√¥micos se correlacionam com o comportamento da audi√™ncia
    2. **Eventos Espec√≠ficos**: O impacto de eventos como competi√ß√µes esportivas, lan√ßamentos de programas concorrentes, etc.
    3. **Volume Social**: Como o volume de conversas nas redes sociais se relaciona com a audi√™ncia TV

    Estas an√°lises ajudam a contextualizar o desempenho da TV Linear dentro do ambiente mais amplo em que opera.

    **Dica**: A an√°lise por hora √© especialmente √∫til para entender o impacto de eventos espec√≠ficos que ocorrem em hor√°rios determinados, como jogos de futebol ou programas de TV concorrentes.
    """)

    granularity = st.selectbox(
        "Selecione a granularidade:",
        options=["Hor√°rio", "Di√°rio", "Semanal"],
        index=0  # Default to "Hor√°rio"
    )

    # Get the selected dataframe
    if granularity == "Di√°rio":
        selected_df = df_daily
    elif granularity == "Semanal":
        selected_df = df_weekly
    else:  # "Hor√°rio"
        selected_df = df_hourly

    # Check which external data columns are available
    economic_cols = [col for col in selected_df.columns if col in [
        'EXTERNO_dolar', 'EXTERNO_unemployment_rate', 'EXTERNO_inflation_ipca', 
        'EXTERNO_selic_rate', 'EXTERNO_indice_cond_economicas'
    ]]

    event_cols = [col for col in selected_df.columns if col in [
        'EXTERNO_FUTEBOL_CONCORRENTE_ON', 'EXTERNO_OLIMPIADAS_24',
        'EXTERNO_SBT_LANCA_PROGRAMA_VIRGINIA', 'EXTERNO_NOTICIA_MORTE_SILVIO_SANTOS',
        'EXTERNO_NETFLIX_LUTA_LOGAN_MIKE'
    ]]

    social_cols = [col for col in selected_df.columns if col in [
        'EXTERNO_quantidade_tweets'
    ]]

    tv_col = 'LINEAR_GLOBO_cov%' if 'LINEAR_GLOBO_cov%' in selected_df.columns else None

    # Calculate overall correlation metrics for each category
    st.subheader("√çndice de Correla√ß√£o por Categoria")

    st.markdown("""
    Os √≠ndices abaixo mostram a correla√ß√£o m√©dia de cada categoria de fatores externos com a audi√™ncia da TV Linear (cov%).
    Valores mais pr√≥ximos de 1.0 indicam maior poder explicativo sobre a audi√™ncia.
    """)

    col1, col2, col3 = st.columns(3)

    # Economic indicators correlation
    eco_corr = 0
    if economic_cols and tv_col:
        # Filter data where both economic indicators and tv_col have valid values
        valid_eco_data = selected_df.dropna(subset=economic_cols + [tv_col])
        
        if not valid_eco_data.empty:
            eco_corrs = []
            for col in economic_cols:
                # Check if column has any non-missing values
                if not valid_eco_data[col].isna().all():
                    corr = abs(valid_eco_data[col].corr(valid_eco_data[tv_col]))
                    if not pd.isna(corr):  # Only include valid correlations
                        eco_corrs.append(corr)
            
            if eco_corrs:
                eco_corr = sum(eco_corrs) / len(eco_corrs)

    with col1:
        st.metric(
            "Indicadores Econ√¥micos",
            f"{eco_corr:.2f}",
            help="Correla√ß√£o m√©dia dos indicadores econ√¥micos com a audi√™ncia (cov%)"
        )

    # Events correlation
    event_corr = 0
    if event_cols and tv_col:
        # Filter data where both events and tv_col have valid values
        valid_events_data = selected_df.dropna(subset=event_cols + [tv_col])
        
        if not valid_events_data.empty:
            event_corrs = []
            for col in event_cols:
                # Check if column has any variation (not all zeros or ones)
                if valid_events_data[col].std() > 0:
                    corr = abs(valid_events_data[col].corr(valid_events_data[tv_col]))
                    if not pd.isna(corr):  # Only include valid correlations
                        event_corrs.append(corr)
            
            if event_corrs:
                event_corr = sum(event_corrs) / len(event_corrs)

    with col2:
        st.metric(
            "Eventos",
            f"{event_corr:.2f}",
            help="Correla√ß√£o m√©dia dos eventos externos com a audi√™ncia (cov%)"
        )

    # Social volume correlation
    social_corr = 0
    if 'EXTERNO_quantidade_tweets' in selected_df.columns and tv_col:
        # Filter data where both tweets and tv_col have valid values
        valid_social_data = selected_df.dropna(subset=['EXTERNO_quantidade_tweets', tv_col])
        
        if not valid_social_data.empty and valid_social_data['EXTERNO_quantidade_tweets'].std() > 0:
            social_corr = abs(valid_social_data['EXTERNO_quantidade_tweets'].corr(valid_social_data[tv_col]))
            if pd.isna(social_corr):  # Handle NaN correlation
                social_corr = 0

    with col3:
        st.metric(
            "Volume Social",
            f"{social_corr:.2f}",
            help="Correla√ß√£o do volume de tweets com a audi√™ncia (cov%)"
        )

    # Create tabs for different categories of analysis
    tabs = st.tabs(["Indicadores Econ√¥micos", "Eventos", "Volume Social"])

    # 3. Economic Indicators Analysis Tab
    with tabs[0]:
        st.subheader("An√°lise de Indicadores Econ√¥micos")
        
        st.markdown("""
        Os indicadores econ√¥micos podem influenciar significativamente os h√°bitos de consumo de m√≠dia.
        Por exemplo, em per√≠odos de maior desemprego, as pessoas podem passar mais tempo em casa assistindo TV,
        enquanto infla√ß√£o alta pode levar √† redu√ß√£o de gastos com entretenimento pago.
        
        O gr√°fico abaixo mostra a evolu√ß√£o dos principais indicadores econ√¥micos normalizados comparados
        com a evolu√ß√£o da audi√™ncia TV Linear da Globo.
        """)
        
        if economic_cols and tv_col:
            # Filter data where both economic indicators and tv_col have valid values
            valid_eco_data = selected_df.dropna(subset=economic_cols + [tv_col])
            
            if not valid_eco_data.empty:
                # Create time series chart comparing economic indicators with TV audience
                fig = make_subplots(specs=[[{"secondary_y": True}]])
                
                # Add TV audience line
                fig.add_trace(
                    go.Scatter(
                        x=valid_eco_data['data_hora'],
                        y=valid_eco_data[tv_col],
                        name='Audi√™ncia TV (cov%)',
                        line=dict(color='rgb(31, 119, 180)', width=3)
                    ),
                    secondary_y=False
                )
                
                # Add economic indicators (normalized)
                colors = ['rgb(255, 127, 14)', 'rgb(44, 160, 44)', 'rgb(214, 39, 40)', 
                        'rgb(148, 103, 189)', 'rgb(140, 86, 75)']
                
                for i, col in enumerate(economic_cols):
                    # Only include columns with valid data
                    if not valid_eco_data[col].isna().all():
                        # Normalize the indicator for better visualization
                        min_val = valid_eco_data[col].min()
                        max_val = valid_eco_data[col].max()
                        if max_val > min_val:  # Avoid division by zero
                            normalized = (valid_eco_data[col] - min_val) / (max_val - min_val) * valid_eco_data[tv_col].max()
                            
                            # Clean up column name for display
                            display_name = col.replace('EXTERNO_', '').replace('_', ' ').title()
                            
                            fig.add_trace(
                                go.Scatter(
                                    x=valid_eco_data['data_hora'],
                                    y=normalized,
                                    name=display_name,
                                    line=dict(color=colors[i % len(colors)], dash='dash')
                                ),
                                secondary_y=True
                            )
                
                # Update layout
                fig.update_layout(
                    title=f'Evolu√ß√£o da Audi√™ncia TV vs. Indicadores Econ√¥micos ({granularity})',
                    xaxis_title='Data',
                    yaxis_title='Audi√™ncia TV (cov%)',
                    yaxis2_title='Indicadores (Normalizados)',
                    legend_title='M√©tricas',
                    hovermode="x unified"
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Create correlation matrix between economic indicators and audience metrics
                st.markdown("### Correla√ß√£o entre Indicadores Econ√¥micos e M√©tricas de Audi√™ncia")
                
                st.markdown("""
                A tabela abaixo mostra a correla√ß√£o entre diferentes indicadores econ√¥micos e m√©tricas de audi√™ncia TV.
                Uma correla√ß√£o positiva (pr√≥xima de 1) indica que as vari√°veis tendem a aumentar juntas,
                enquanto uma correla√ß√£o negativa (pr√≥xima de -1) indica uma rela√ß√£o inversa.
                Valores pr√≥ximos de zero indicam pouca ou nenhuma rela√ß√£o linear.
                """)
                
                # Select audience metrics
                audience_metrics = [col for col in valid_eco_data.columns if col.startswith('LINEAR_GLOBO_') 
                                and col in ['LINEAR_GLOBO_cov%', 'LINEAR_GLOBO_shr%', 'LINEAR_GLOBO_tvr%']]
                
                if audience_metrics:
                    # Calculate correlation matrix
                    corr_matrix = valid_eco_data[economic_cols + audience_metrics].corr()
                    
                    # Extract correlations between economic indicators and audience metrics
                    eco_audience_corr = corr_matrix.loc[economic_cols, audience_metrics]
                    
                    # Create a clean correlation matrix for display
                    clean_rows = [col.replace('EXTERNO_', '').replace('_', ' ').title() for col in eco_audience_corr.index]
                    clean_cols = [col.replace('LINEAR_GLOBO_', '').replace('%', ' %') for col in eco_audience_corr.columns]
                    
                    clean_corr = pd.DataFrame(
                        eco_audience_corr.values,
                        index=clean_rows,
                        columns=clean_cols
                    )
                    
                    # Create heatmap
                    fig_heatmap = px.imshow(
                        clean_corr,
                        text_auto=True,
                        aspect="auto",
                        color_continuous_scale=["red", "white", "green"],
                        labels=dict(x="M√©trica de Audi√™ncia", y="Indicador Econ√¥mico", color="Correla√ß√£o"),
                        title="Correla√ß√£o entre Indicadores Econ√¥micos e M√©tricas de Audi√™ncia"
                    )
                    
                    st.plotly_chart(fig_heatmap, use_container_width=True)
                    
                    # Generate insights based on correlations
                    st.markdown("### Insights Principais")
                    
                    # Find strongest positive and negative correlations
                    eco_audience_flat = eco_audience_corr.unstack()
                    strongest_positive = eco_audience_flat.nlargest(1)
                    strongest_negative = eco_audience_flat.nsmallest(1)
                    
                    # Display insights
                    if not strongest_positive.empty:
                        pos_val = strongest_positive.values[0]
                        pos_idx = strongest_positive.index[0]
                        pos_eco = pos_idx[0].replace('EXTERNO_', '').replace('_', ' ').title()
                        pos_aud = pos_idx[1].replace('LINEAR_GLOBO_', '').replace('%', ' %')
                        
                        if pos_val > 0.3:
                            st.success(f"**Rela√ß√£o Positiva Forte:** {pos_eco} tem correla√ß√£o positiva de {pos_val:.2f} com {pos_aud}, "
                                    f"sugerindo que aumentos neste indicador est√£o associados a maiores n√≠veis de audi√™ncia.")
                    
                    if not strongest_negative.empty:
                        neg_val = strongest_negative.values[0]
                        neg_idx = strongest_negative.index[0]
                        neg_eco = neg_idx[0].replace('EXTERNO_', '').replace('_', ' ').title()
                        neg_aud = neg_idx[1].replace('LINEAR_GLOBO_', '').replace('%', ' %')
                        
                        if neg_val < -0.3:
                            st.error(f"**Rela√ß√£o Negativa Forte:** {neg_eco} tem correla√ß√£o negativa de {neg_val:.2f} com {neg_aud}, "
                                f"sugerindo que aumentos neste indicador est√£o associados a menores n√≠veis de audi√™ncia.")
                    
                    # Additional insights based on specific economic indicators
                    if 'EXTERNO_unemployment_rate' in economic_cols and 'LINEAR_GLOBO_cov%' in audience_metrics:
                        unemp_corr = corr_matrix.loc['EXTERNO_unemployment_rate', 'LINEAR_GLOBO_cov%']
                        
                        if unemp_corr > 0.3:
                            st.info(f"**Desemprego e Audi√™ncia:** A correla√ß√£o de {unemp_corr:.2f} entre desemprego e audi√™ncia "
                                f"sugere que em per√≠odos de maior desemprego h√° maior consumo de TV Linear, possivelmente "
                                f"devido a mais pessoas em casa e/ou a busca por entretenimento de menor custo.")
                        elif unemp_corr < -0.3:
                            st.info(f"**Desemprego e Audi√™ncia:** A correla√ß√£o de {unemp_corr:.2f} entre desemprego e audi√™ncia "
                                f"sugere que em per√≠odos de maior desemprego h√° menor consumo de TV Linear, possivelmente "
                                f"indicando mudan√ßa para alternativas de entretenimento mais econ√¥micas.")
                    
                    if 'EXTERNO_inflation_ipca' in economic_cols and 'LINEAR_GLOBO_cov%' in audience_metrics:
                        infl_corr = corr_matrix.loc['EXTERNO_inflation_ipca', 'LINEAR_GLOBO_cov%']
                        
                        if abs(infl_corr) > 0.3:
                            dir_word = "maior" if infl_corr > 0 else "menor"
                            st.info(f"**Infla√ß√£o e Audi√™ncia:** A correla√ß√£o de {infl_corr:.2f} entre infla√ß√£o (IPCA) e audi√™ncia "
                                f"sugere que per√≠odos de infla√ß√£o mais alta est√£o associados a {dir_word} consumo de TV Linear.")
            else:
                st.warning("Dados insuficientes para an√°lise de indicadores econ√¥micos.")
        else:
            st.warning("Dados econ√¥micos ou de audi√™ncia n√£o est√£o dispon√≠veis.")

    # 4. Events Analysis Tab
    with tabs[1]:
        st.subheader("An√°lise de Eventos")
        
        # Different explanations based on granularity
        if granularity == "Hor√°rio":
            st.markdown("""
            Eventos espec√≠ficos como competi√ß√µes esportivas, programas concorrentes, ou acontecimentos relevantes 
            podem impactar significativamente a audi√™ncia de TV em hor√°rios espec√≠ficos. Esta an√°lise quantifica 
            o impacto desses eventos hora a hora, permitindo entender como afetam a audi√™ncia precisamente nos
            momentos em que ocorrem.
            
            O gr√°fico abaixo mostra a evolu√ß√£o hor√°ria da audi√™ncia com marcadores nos momentos em que ocorreram eventos espec√≠ficos.
            """)
        else:
            st.markdown("""
            Eventos espec√≠ficos como competi√ß√µes esportivas, programas concorrentes, ou acontecimentos relevantes 
            podem impactar significativamente a audi√™ncia de TV. Esta an√°lise quantifica o impacto desses eventos,
            permitindo entender melhor como o contexto externo influencia os resultados de audi√™ncia.
            
            O gr√°fico abaixo mostra a evolu√ß√£o da audi√™ncia com marcadores nos dias em que ocorreram eventos espec√≠ficos.
            """)
        
        if event_cols and tv_col:
            # Filter data where at least one event and tv_col have valid values
            valid_events = []
            for col in event_cols:
                if selected_df[col].std() > 0:  # Check if column has variation
                    valid_events.append(col)
            
            if valid_events:
                # Create a dataframe for plotting with valid events only
                plot_df = selected_df[['data_hora', tv_col] + valid_events].dropna().copy()
                
                if not plot_df.empty:
                    # Convert event columns to descriptive names
                    for event_col in valid_events:
                        event_name = event_col.replace('EXTERNO_', '').replace('_', ' ').title()
                        plot_df[event_name] = plot_df[event_col]
                    
                    # Create timeline with event markers
                    fig = go.Figure()
                    
                    # Add TV audience line
                    fig.add_trace(
                        go.Scatter(
                            x=plot_df['data_hora'],
                            y=plot_df[tv_col],
                            name='Audi√™ncia TV (cov%)',
                            line=dict(color='rgb(31, 119, 180)', width=2)
                        )
                    )
                    
                    # Add markers for each event
                    colors = ['rgb(255, 127, 14)', 'rgb(44, 160, 44)', 'rgb(214, 39, 40)', 
                            'rgb(148, 103, 189)', 'rgb(140, 86, 75)']
                    
                    for i, event_col in enumerate(valid_events):
                        event_name = event_col.replace('EXTERNO_', '').replace('_', ' ').title()
                        
                        # Filter for days when the event occurred
                        event_days = plot_df[plot_df[event_col] > 0]
                        
                        if not event_days.empty:
                            fig.add_trace(
                                go.Scatter(
                                    x=event_days['data_hora'],
                                    y=event_days[tv_col],
                                    mode='markers',
                                    name=event_name,
                                    marker=dict(
                                        size=10,
                                        color=colors[i % len(colors)],
                                        symbol='diamond'
                                    )
                                )
                            )
                    
                    # Update layout
                    time_unit = "hor√°rio" if granularity == "Hor√°rio" else "di√°rio" if granularity == "Di√°rio" else "semanal"
                    fig.update_layout(
                        title=f'Evolu√ß√£o {time_unit} da Audi√™ncia TV com Marcadores de Eventos ({granularity})',
                        xaxis_title='Data e Hora' if granularity == "Hor√°rio" else 'Data',
                        yaxis_title='Audi√™ncia TV (cov%)',
                        legend_title='Eventos',
                        hovermode="closest"
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Create impact analysis table
                    st.markdown("### Impacto dos Eventos na Audi√™ncia TV")
                    
                    if granularity == "Hor√°rio":
                        st.markdown("""
                        A tabela abaixo quantifica o impacto de diferentes tipos de eventos na audi√™ncia de TV por hora.
                        Para cada evento, calculamos a diferen√ßa percentual m√©dia na audi√™ncia durante as horas em que o evento
                        ocorreu comparado com horas sem o evento. Isso permite entender o impacto preciso no momento exato de ocorr√™ncia.
                        """)
                    else:
                        st.markdown("""
                        A tabela abaixo quantifica o impacto de diferentes tipos de eventos na audi√™ncia de TV.
                        Para cada evento, calculamos a diferen√ßa percentual m√©dia na audi√™ncia durante o evento
                        comparado com per√≠odos sem o evento.
                        """)
                    
                    # Calculate impact for each event
                    impact_data = []
                    
                    for event_col in valid_events:
                        event_name = event_col.replace('EXTERNO_', '').replace('_', ' ').title()
                        
                        # Calculate audience with and without event
                        event_on = plot_df[plot_df[event_col] > 0][tv_col].mean()
                        event_off = plot_df[plot_df[event_col] == 0][tv_col].mean()
                        
                        # Calculate impact percentage
                        if event_off > 0:  # Avoid division by zero
                            impact_pct = ((event_on / event_off) - 1) * 100
                            
                            # Count occurrences
                            occurrences = plot_df[plot_df[event_col] > 0].shape[0]
                            
                            impact_data.append({
                                "Evento": event_name,
                                "Impacto na Audi√™ncia (%)": f"{impact_pct:.2f}%",
                                "Dire√ß√£o": "Positivo" if impact_pct > 0 else "Negativo",
                                "Ocorr√™ncias": occurrences
                            })
                    
                    if impact_data:
                        # Convert to DataFrame
                        impact_df = pd.DataFrame(impact_data)
                        
                        # Display as table
                        st.dataframe(impact_df, hide_index=True, use_container_width=True)
                        
                        # Generate insights based on impact
                        st.markdown("### Insights sobre Eventos")
                        
                        # Find events with strongest positive and negative impacts
                        pos_events = [event for event in impact_data if "Positivo" in event["Dire√ß√£o"]]
                        neg_events = [event for event in impact_data if "Negativo" in event["Dire√ß√£o"]]
                        
                        # Sort by impact magnitude
                        pos_events.sort(key=lambda x: float(x["Impacto na Audi√™ncia (%)"].replace("%", "")), reverse=True)
                        neg_events.sort(key=lambda x: float(x["Impacto na Audi√™ncia (%)"].replace("%", "")))
                        
                        if pos_events:
                            top_pos = pos_events[0]
                            pos_impact = float(top_pos["Impacto na Audi√™ncia (%)"].replace("%", ""))
                            
                            if pos_impact > 5:  # Only show if impact is significant
                                time_text = "horas" if granularity == "Hor√°rio" else "dias" if granularity == "Di√°rio" else "semanas"
                                st.success(f"**Evento com Maior Impacto Positivo:** {top_pos['Evento']} aumenta a audi√™ncia "
                                        f"em {top_pos['Impacto na Audi√™ncia (%)']} em m√©dia, baseado em {top_pos['Ocorr√™ncias']} {time_text}.")
                        
                        if neg_events:
                            top_neg = neg_events[0]
                            neg_impact = float(top_neg["Impacto na Audi√™ncia (%)"].replace("%", ""))
                            
                            if neg_impact < -5:  # Only show if impact is significant
                                time_text = "horas" if granularity == "Hor√°rio" else "dias" if granularity == "Di√°rio" else "semanas"
                                st.error(f"**Evento com Maior Impacto Negativo:** {top_neg['Evento']} reduz a audi√™ncia "
                                    f"em {top_neg['Impacto na Audi√™ncia (%)']} em m√©dia, baseado em {top_neg['Ocorr√™ncias']} {time_text}.")
                        
                        # Additional analysis for specific event types
                        football_events = [event for event in impact_data if "Futebol" in event["Evento"]]
                        if football_events:
                            football = football_events[0]
                            impact = float(football["Impacto na Audi√™ncia (%)"].replace("%", ""))
                            
                            if abs(impact) > 5:
                                direction = "aumenta" if impact > 0 else "reduz"
                                
                                # Add hourly specific insight
                                if granularity == "Hor√°rio":
                                    st.info(f"**Impacto de Eventos Esportivos:** Futebol {direction} a audi√™ncia em "
                                        f"{abs(impact):.2f}% durante as horas em que ocorre, sugerindo que as transmiss√µes esportivas "
                                        f"{'atraem' if impact > 0 else 'competem pela'} audi√™ncia da TV Linear no momento exato "
                                        f"em que acontecem.")
                                else:
                                    st.info(f"**Impacto de Eventos Esportivos:** Futebol {direction} a audi√™ncia em "
                                        f"{abs(impact):.2f}%, sugerindo que a programa√ß√£o esportiva {'atrai' if impact > 0 else 'compete pela'} "
                                        f"audi√™ncia da TV Linear.")
                    else:
                        st.warning("N√£o foi poss√≠vel calcular o impacto dos eventos na audi√™ncia.")
                else:
                    st.warning("Dados insuficientes para an√°lise de eventos.")
            else:
                st.warning("N√£o foram encontrados eventos v√°lidos no per√≠odo analisado.")
        else:
            st.warning("Dados de eventos ou de audi√™ncia n√£o est√£o dispon√≠veis.")

    # 5. Social Volume Analysis Tab
    with tabs[2]:
        st.subheader("An√°lise de Volume Social")
        
        if granularity == "Hor√°rio":
            st.markdown("""
            O volume de conversas nas redes sociais pode variar significativamente ao longo do dia e impactar a audi√™ncia TV hora a hora.
            Programas que geram conversa√ß√£o intensa em tempo real podem atrair espectadores adicionais, enquanto assuntos
            virais podem desviar a aten√ß√£o da TV em hor√°rios espec√≠ficos.
            
            Esta an√°lise examina a rela√ß√£o entre o volume hor√°rio de tweets e m√©tricas de audi√™ncia da TV Linear.
            """)
        else:
            st.markdown("""
            O volume de conversas nas redes sociais pode ser tanto um indicador como um driver da audi√™ncia de TV.
            Programas que geram mais conversa√ß√£o podem atrair novos espectadores, enquanto assuntos muito discutidos
            nas redes sociais podem desviar a aten√ß√£o da TV.
            
            Esta an√°lise examina a rela√ß√£o entre o volume de tweets e m√©tricas de audi√™ncia da TV Linear.
            """)
        
        # Check if we have tweet data
        if 'EXTERNO_quantidade_tweets' in selected_df.columns and tv_col:
            # Filter data where both tweets and tv_col have valid values
            valid_social_data = selected_df.dropna(subset=['EXTERNO_quantidade_tweets', tv_col])
            
            # Also filter for non-zero tweet values
            valid_social_data = valid_social_data[valid_social_data['EXTERNO_quantidade_tweets'] > 0]
            
            if not valid_social_data.empty:
                # Create time series chart comparing tweet volume with TV audience
                fig = make_subplots(specs=[[{"secondary_y": True}]])
                
                # Add TV audience line
                fig.add_trace(
                    go.Scatter(
                        x=valid_social_data['data_hora'],
                        y=valid_social_data[tv_col],
                        name='Audi√™ncia TV (cov%)',
                        line=dict(color='rgb(31, 119, 180)', width=3)
                    ),
                    secondary_y=False
                )
                
                # Add tweet volume
                fig.add_trace(
                    go.Scatter(
                        x=valid_social_data['data_hora'],
                        y=valid_social_data['EXTERNO_quantidade_tweets'],
                        name='Volume de Tweets',
                        line=dict(color='rgb(255, 127, 14)', width=2)
                    ),
                    secondary_y=True
                )
                
                # Update layout
                time_unit = "" if granularity == "Hor√°rio" else "Di√°ria" if granularity == "Di√°rio" else "Semanal"
                fig.update_layout(
                    title=f'Evolu√ß√£o {time_unit} da Audi√™ncia TV vs. Volume de Tweets ({granularity})',
                    xaxis_title='Data e Hora' if granularity == "Hor√°rio" else 'Data',
                    yaxis_title='Audi√™ncia TV (cov%)',
                    yaxis2_title='Quantidade de Tweets',
                    legend_title='M√©tricas',
                    hovermode="x unified"
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Create scatter plot for correlation analysis
                st.markdown("### Correla√ß√£o entre Volume de Tweets e Audi√™ncia TV")
                
                fig_scatter = px.scatter(
                    valid_social_data,
                    x='EXTERNO_quantidade_tweets',
                    y=tv_col,
                    trendline="ols",
                    labels={
                        'EXTERNO_quantidade_tweets': 'Quantidade de Tweets',
                        tv_col: 'Audi√™ncia TV (cov%)'
                    },
                    title='Rela√ß√£o entre Volume de Tweets e Audi√™ncia TV'
                )
                
                st.plotly_chart(fig_scatter, use_container_width=True)
                
                # Calculate correlation and regression
                tweets_corr = valid_social_data['EXTERNO_quantidade_tweets'].corr(valid_social_data[tv_col])
                
                # Create lag analysis if not hourly (no lag analysis for hourly makes less sense)
                if granularity != "Hor√°rio":
                    st.markdown("### An√°lise de Lag: Tweets vs. Audi√™ncia")
                    
                    st.markdown("""
                    Esta an√°lise verifica se um aumento no volume de tweets precede ou sucede 
                    um aumento na audi√™ncia TV. Um lag positivo significativo sugere que a conversa√ß√£o
                    social pode funcionar como um preditor da audi√™ncia futura.
                    """)
                    
                    # Create lag columns
                    lags = [1, 2, 3, 7]  # Look at 1, 2, 3, and 7 days lag
                    lag_corrs = []
                    
                    for lag in lags:
                        lag_col = f'tweets_lag_{lag}'
                        valid_social_data[lag_col] = valid_social_data['EXTERNO_quantidade_tweets'].shift(lag)
                        
                        # Calculate correlation with audience, excluding NaN values
                        lag_data = valid_social_data.dropna(subset=[lag_col, tv_col])
                        
                        if not lag_data.empty:
                            corr = lag_data[lag_col].corr(lag_data[tv_col])
                            if not pd.isna(corr):  # Only include valid correlations
                                lag_corrs.append({
                                    'Lag (dias)': lag,
                                    'Correla√ß√£o': corr
                                })
                    
                    if lag_corrs:
                        # Convert to DataFrame
                        lag_df = pd.DataFrame(lag_corrs)
                        
                        # Create bar chart
                        fig_lag = px.bar(
                            lag_df,
                            x='Lag (dias)',
                            y='Correla√ß√£o',
                            title='Correla√ß√£o entre Volume de Tweets (com lag) e Audi√™ncia TV',
                            labels={
                                'Lag (dias)': 'Tweets Defasados (dias)',
                                'Correla√ß√£o': 'Correla√ß√£o com Audi√™ncia TV'
                            },
                            color='Correla√ß√£o',
                            color_continuous_scale=['red', 'yellow', 'green']
                        )
                        
                        st.plotly_chart(fig_lag, use_container_width=True)
                else:
                    # For hourly analysis, provide insight about real-time social engagement
                    st.markdown("### An√°lise de Engajamento Social em Tempo Real")
                    
                    st.markdown("""
                    Para dados por hora, a an√°lise de correla√ß√£o em tempo real √© mais relevante que a an√°lise de lag.
                    A correla√ß√£o atual mostra se as pessoas est√£o engajadas nas redes sociais durante o mesmo per√≠odo
                    em que est√£o assistindo TV, o que pode indicar o uso de "segunda tela" ou conversa√ß√£o social
                    sobre os programas em andamento.
                    """)
                
                # Generate insights based on correlation
                st.markdown("### Insights sobre Volume Social")
                
                # Direct correlation insight
                if not pd.isna(tweets_corr):
                    if abs(tweets_corr) > 0.3:
                        direction = "positiva" if tweets_corr > 0 else "negativa"
                        relation = "aumentam juntos" if tweets_corr > 0 else "t√™m rela√ß√£o inversa"
                        
                        if granularity == "Hor√°rio":
                            st.info(f"**Correla√ß√£o {direction}:** A correla√ß√£o de {tweets_corr:.2f} entre volume de tweets e audi√™ncia por hora "
                                f"sugere que estas m√©tricas {relation}. Isso pode indicar que {'os espectadores est√£o usando as redes sociais como segunda tela durante os programas' if tweets_corr > 0 else 'maior atividade nas redes sociais pode desviar aten√ß√£o da TV em hor√°rios espec√≠ficos'}.")
                        else:
                            st.info(f"**Correla√ß√£o {direction}:** A correla√ß√£o de {tweets_corr:.2f} entre volume de tweets e audi√™ncia "
                                f"sugere que estas m√©tricas {relation}. Isso pode indicar que {'programas mais assistidos geram mais conversa√ß√£o social' if tweets_corr > 0 else 'maior atividade nas redes sociais pode desviar aten√ß√£o da TV'}.")
                
                # If we have lag analysis, show those insights
                if granularity != "Hor√°rio" and 'lag_corrs' in locals() and lag_corrs:
                    max_lag_corr = max(lag_corrs, key=lambda x: abs(x['Correla√ß√£o']))
                    
                    if abs(max_lag_corr['Correla√ß√£o']) > 0.3:
                        direction = "positiva" if max_lag_corr['Correla√ß√£o'] > 0 else "negativa"
                        effect = "preditor" if max_lag_corr['Correla√ß√£o'] > 0 else "indicador de poss√≠vel queda"
                        
                        st.success(f"**Efeito Temporal:** A correla√ß√£o {direction} mais forte ({max_lag_corr['Correla√ß√£o']:.2f}) "
                                f"ocorre com {max_lag_corr['Lag (dias)']} dia(s) de defasagem, sugerindo que o volume de tweets "
                                f"pode ser um {effect} da audi√™ncia TV futura.")
                
                # Hourly specific insight
                if granularity == "Hor√°rio":
                    # Analyze correlation during prime time vs other times
                    prime_time_hours = list(range(19, 23))  # 7pm to 10pm
                    
                    prime_df = valid_social_data[valid_social_data['data_hora'].dt.hour.isin(prime_time_hours)]
                    non_prime_df = valid_social_data[~valid_social_data['data_hora'].dt.hour.isin(prime_time_hours)]
                    
                    if not prime_df.empty and not non_prime_df.empty:
                        prime_corr = prime_df['EXTERNO_quantidade_tweets'].corr(prime_df[tv_col])
                        non_prime_corr = non_prime_df['EXTERNO_quantidade_tweets'].corr(non_prime_df[tv_col])
                        
                        if not pd.isna(prime_corr) and not pd.isna(non_prime_corr) and abs(prime_corr - non_prime_corr) > 0.2:
                            stronger = "hor√°rio nobre" if abs(prime_corr) > abs(non_prime_corr) else "fora do hor√°rio nobre"
                            st.success(f"**Diferen√ßa por Hor√°rio:** A correla√ß√£o entre tweets e audi√™ncia √© mais forte durante o {stronger} "
                                    f"({prime_corr:.2f} vs {non_prime_corr:.2f}), sugerindo que "
                                    f"{'o comportamento de segunda tela √© mais prevalente no hor√°rio nobre' if stronger == 'hor√°rio nobre' else 'o uso de redes sociais durante o dia tem impacto maior na audi√™ncia fora do hor√°rio nobre'}.")
                
                # Quantification insight
                if not pd.isna(tweets_corr) and abs(tweets_corr) > 0.3:
                    # Fit a simple linear regression model
                    X = sm.add_constant(valid_social_data['EXTERNO_quantidade_tweets'])
                    y = valid_social_data[tv_col]
                    model = sm.OLS(y, X).fit()
                    
                    # Get coefficient to quantify impact
                    coef = model.params[1]
                    
                    if abs(coef) > 0.001:  # Only show if effect size is meaningful
                        direction = "aumento" if coef > 0 else "redu√ß√£o"
                        
                        qty_text = "por hora" if granularity == "Hor√°rio" else "por dia" if granularity == "Di√°rio" else "por semana"
                        st.info(f"**Quantifica√ß√£o do Impacto:** A cada 1000 tweets adicionais {qty_text}, observa-se {direction} de "
                            f"{abs(coef*1000):.3f} pontos percentuais na audi√™ncia TV.")
            else:
                st.warning("Dados insuficientes para an√°lise de volume social no per√≠odo selecionado.")
        else:
            st.warning("Dados sobre volume de tweets (EXTERNO_quantidade_tweets) n√£o est√£o dispon√≠veis.")

    # 8. Final notes - always show
    with st.expander("Informa√ß√µes sobre a an√°lise de fatores externos"):
        st.markdown("""
        ### Fonte dos Dados

        **Indicadores Econ√¥micos**: Os dados econ√¥micos s√£o obtidos de fontes oficiais como o Banco Central do Brasil e o IBGE.

        **Eventos**: Os eventos s√£o identificados e categorizados manualmente com base em um calend√°rio de eventos relevantes.

        **Volume Social**: Os dados de volume de tweets s√£o obtidos via API do Twitter/X, com foco em termos relacionados √† m√≠dia e entretenimento.

        ### Considera√ß√µes Metodol√≥gicas

        1. **Correla√ß√£o n√£o implica causalidade**: Embora identifiquemos correla√ß√µes entre fatores externos e audi√™ncia, isso n√£o necessariamente indica uma rela√ß√£o causal. Outros fatores n√£o observados podem estar influenciando ambas as vari√°veis.

        2. **Limita√ß√µes temporais**: A an√°lise considera apenas o per√≠odo coberto pelos dados dispon√≠veis, que pode n√£o representar todos os ciclos econ√¥micos ou sazonalidades.

        3. **Simplifica√ß√£o de eventos**: Eventos s√£o tratados como vari√°veis bin√°rias (ocorreram ou n√£o), sem considerar sua intensidade ou dura√ß√£o espec√≠fica.

        4. **Modelo linear**: O modelo explicativo integrado assume rela√ß√µes lineares entre fatores externos e audi√™ncia, o que pode n√£o capturar completamente rela√ß√µes mais complexas.
        
        5. **Granularidade dos dados**: A an√°lise hor√°ria permite maior precis√£o ao examinar o impacto imediato de eventos, enquanto a an√°lise di√°ria ou semanal captura tend√™ncias mais amplas.
        
        6. **Compara√ß√µes v√°lidas**: Para cada an√°lise, consideramos apenas os per√≠odos em que existem dados v√°lidos para todas as vari√°veis envolvidas, garantindo que as compara√ß√µes sejam consistentes e representativas.
        """)